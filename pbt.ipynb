{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pbt: Population Based Training\n",
    "\n",
    "Code to replicate figure 2 of [Population Based Training of Neural Networks, Jaderberg et al](https://arxiv.org/abs/1711.09846)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "_ = np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PBT worker\n",
    "\n",
    "class Worker():\n",
    "    \n",
    "    def __init__(self, theta, h, objective, surrogate_objective, id):\n",
    "\n",
    "        self.id = id\n",
    "        \n",
    "        self._history = {\"theta\" : [], \"h\" : [], \"score\" : []}\n",
    "        \n",
    "        with tf.name_scope(\"worker_\" + str(self.id)):\n",
    "            self.h_ = tf.placeholder(tf.float32, shape=np.shape(h), name=\"input_h\")\n",
    "            self.theta_ = tf.placeholder(tf.float32, shape=np.shape(theta), name=\"input_theta\")\n",
    "            self.h = tf.Variable(h, name=\"hyperparam\", dtype=tf.float32)\n",
    "            self.theta = tf.Variable(theta, name=\"theta\", dtype=tf.float32)\n",
    "            \n",
    "            self.h_assign = tf.assign(self.h, self.h_)\n",
    "            self.theta_assign = tf.assign(self.theta, self.theta_)\n",
    "        \n",
    "        self.objective = objective(self.theta)\n",
    "        self.surrogate_objective = surrogate_objective(self.theta, self.h)\n",
    "        self.loss, self.update_step = self._init_graph()\n",
    "    \n",
    "    def _init_graph(self):\n",
    "        loss = -1 * self.surrogate_objective\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "        update_step = optimizer.minimize(loss)\n",
    "        return loss, update_step\n",
    "    \n",
    "    @property\n",
    "    def history(self):\n",
    "        return {\n",
    "            \"theta\" : np.vstack(self._history['theta']),\n",
    "            \"h\"     : np.vstack(self._history['h']),\n",
    "            \"score\" : np.array(self._history['score']),\n",
    "        }\n",
    "    \n",
    "    def _log(self, sess):\n",
    "        theta, h = sess.run([self.theta, self.h])\n",
    "        self._history['theta'].append(np.copy(theta))\n",
    "        self._history['h'].append(np.copy(h))\n",
    "        self._history['score'].append(self.eval(sess))\n",
    "    \n",
    "    \n",
    "    def step(self, sess):\n",
    "        \"\"\" Take an optimization step, given current hyperparemeters and surrogate objective \"\"\"\n",
    "        self._log(sess)\n",
    "        loss, _ = sess.run([self.loss, self.update_step])\n",
    "        return loss\n",
    "    \n",
    "    def eval(self, sess):\n",
    "        \"\"\" Evalute actual objective -- eg measure accuracy on the hold-out set \"\"\"\n",
    "        \n",
    "        return sess.run(self.objective)\n",
    "    \n",
    "    def exploit(self, population ,sess):\n",
    "        \"\"\" Copy theta from best member of the population \"\"\"\n",
    "        \n",
    "        current_scores = [{\n",
    "            \"id\": worker.id,\n",
    "            \"score\": worker.eval(sess)\n",
    "        } for worker in population]\n",
    "        \n",
    "        best_worker = sorted(current_scores, key=lambda x: x['score'])[-1]\n",
    "        \n",
    "        if best_worker['id'] != self.id:\n",
    "            theta = sess.run(population[best_worker['id']].theta)\n",
    "            sess.run(self.theta_assign, feed_dict={self.theta_:theta})\n",
    "    \n",
    "    def explore(self, sess, sd=0.1):\n",
    "        \"\"\" Add normal noise to hyperparameter vector \"\"\"\n",
    "        \n",
    "        h = sess.run(self.h) + np.random.random() * sd\n",
    "        sess.run(self.h_assign, feed_dict={self.h_: h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(do_explore=False, do_exploit=False, interval=5, n_steps=200):\n",
    "    \n",
    "    # Define objective functions\n",
    "    objective = lambda theta: tf.constant(1.2) - tf.reduce_sum(tf.square(theta))\n",
    "    surrogate_objective = lambda theta, h: tf.constant(1.2) - tf.reduce_sum(tf.square(h*theta))\n",
    "    \n",
    "    # Create population\n",
    "    population = [\n",
    "        Worker(\n",
    "            theta=np.array([0.9,0.9]),\n",
    "            h=np.array([1.0,0.0]),\n",
    "            objective=objective,\n",
    "            surrogate_objective=surrogate_objective,\n",
    "            id=0,\n",
    "        ),\n",
    "        Worker(\n",
    "            theta=np.array([0.9,0.9]),\n",
    "            h=np.array([0.0,1.0]),\n",
    "            objective=objective,\n",
    "            surrogate_objective=surrogate_objective,\n",
    "            id=1,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    # Train\n",
    "    for step in range(n_steps):\n",
    "        for worker in population:\n",
    "            if not (step + 1) % interval:\n",
    "                \n",
    "                if do_exploit:\n",
    "                    worker.exploit(population,sess)\n",
    "                    \n",
    "                if do_explore:\n",
    "                    worker.explore(sess)\n",
    "            \n",
    "            worker.step(sess)\n",
    "    \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments w/ various PBT settings\n",
    "pbt = run_experiment(do_explore=True, do_exploit=True) # Explore and exploit\n",
    "explore = run_experiment(do_explore=True, do_exploit=False) # Explore only\n",
    "exploit = run_experiment(do_explore=False, do_exploit=True) # Exploit only\n",
    "grid = run_experiment(do_explore=False, do_exploit=False) # Independent training runs -- eg, regular grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score(ax, workers, run_name):\n",
    "    \"\"\" Plot performance \"\"\"\n",
    "    for worker in workers:\n",
    "        history = worker.history\n",
    "        _ = ax.plot(history['score'], label=\"%s worker %d\" % (run_name, worker.id), alpha=0.5)\n",
    "    \n",
    "    _ = ax.set_title(run_name)\n",
    "    _ = ax.set_ylim(-1, 1.3)\n",
    "    _ = ax.axhline(1.2, c='lightgrey')\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "plot_score(ax1, pbt, 'pbt')\n",
    "plot_score(ax2, explore, 'explore')\n",
    "plot_score(ax3, exploit, 'exploit')\n",
    "plot_score(ax4, grid, 'grid')\n",
    "_ = plt.tight_layout(pad=1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theta(ax, workers, run_name):\n",
    "    \"\"\" Plot values of theta \"\"\"\n",
    "    for worker in workers:\n",
    "        history = worker.history\n",
    "        _ = ax.scatter(history['theta'][:,0], history['theta'][:,1], \n",
    "            s=2, alpha=0.5, label=\"%s worker %d\" % (run_name, worker.id))\n",
    "    \n",
    "    _ = ax.set_title(run_name)\n",
    "    _ = ax.set_xlim(0, 1)\n",
    "    _ = ax.set_ylim(0, 1)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "plot_theta(ax1, pbt, 'pbt')\n",
    "plot_theta(ax2, explore, 'explore')\n",
    "plot_theta(ax3, exploit, 'exploit')\n",
    "plot_theta(ax4, grid, 'grid')\n",
    "_ = plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_h(ax, workers, run_name):\n",
    "    \"\"\" Plot values of h\"\"\"\n",
    "    for worker in workers:\n",
    "        history = worker.history['h']\n",
    "        _ = ax.scatter(history[:,0], history[:,1], s=2, alpha=0.5, label=\"%s worker %d\"%(run_name, worker.id))\n",
    "    \n",
    "    _ = ax.set_title(run_name)\n",
    "    _ = ax.set_xlim(0,3)\n",
    "    _ = ax.set_ylim(0,3)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "plot_h(ax1, pbt, 'pbt')\n",
    "plot_h(ax2, explore, 'explore')\n",
    "plot_h(ax3, exploit, 'exploit')\n",
    "plot_h(ax4, grid, 'grid')\n",
    "_ = plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
